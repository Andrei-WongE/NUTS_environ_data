---
title: "Technical documentation NUTS1&2 level environmental data"
author: "Andrei Wong Espejo"
format: docx
editor: visual
---

<!-- using quarto install extension quarto-monash/report -->
<!-- using quarto install extension schochastics/academicons -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Prevent scientific notation
options(scipen = 999)

# Load required packages ----
require(quartotemplate)


```


# Introduction:

# Workflow:

Using the NUTS package we can:

-   nuts_classify() detects the NUTS version(s) and level(s) of a data set. Its output can be directly fed into the two other functions.

-   nuts_convert_version() converts your data to a desired NUTS version (2006, 2005, 2013, 2016, 2021). This transformation works in any direction.

-   nuts_aggregate() aggregates data to some upper-level NUTS code, i.e., it transforms NUTS-3 data to the NUTS-2 or NUTS-1 level (but not vice versa).

![](Figures/NUTS_workflow.png){.preview-image width="374" height="453"}

# Obtaining data

GHS (2023) 
Epochs: c(1975, 1980, 1985, 1990, 1995, 2000, 2005, 2005, 2015, 2020, 2025, 2030)
Resolution: 1km
Coordinate System: Mollweide

The combined information result into a new layer (resolution 1Km) which disergards administrative boundaries, and represents the presence and density of population.
In the GHS pop grid, the grid cell value represents the absolute number of inhabitants.

Advantages of population grids, from https://academy.europa.eu/pluginfile.php/17898/mod_scorm/intro/mod4-large.mp4?time=1656319630211 
Do not depend on the shape and size of census units
Do not depend on the boundary of census units
Grid cells have the same size and are stable over time
Grids integrate easily with other data
Grid cells can be assembled into custom zones

ERAS5 ()


NUTS1&2 (2016)


```{r}

```

# Data cleaning and wrangling

The spatial analysis operations to perform are:
- Aggregation: change of scale of the information, from 1km GHS population grid to 25km ERAS5 grid/cmip6-x0.25 grid. This means the reprojection of population grids maintaining volumes and minimising displacement of population.

- Zonal statistics:Summary of rasters by zones, at the NUTS1&2 regions.

_ Warping:  Changing the coordinate system of grids storing population counts is typically a challenging task, due to the need to keep the population totals unchanged (i.e. volume preservation). One critical aspect of population grids is that they represent a given spatial distribution and volume of people (i.e. total number of persons) for the area being represented. This volume (e.g. the population of a country in a given year) should not suffer significant changes when converting such a grid from the coordinate system in which it is produced to another coordinate system. From: ghs-popwarp_user_guide_online.pdf

Currently the number of population grid products with large territorial coverage is increasing, but each of the
products has different assumptions, technical specifications (Leyk et al. 2019) and therefore different fitness
for use. Population grids differ in population concepts, methods for production, spatial and temporal
resolution, temporal coverage, distribution policy and also spatial reference (coordinate system).

Operation: GHS 1km grid using Mollewiede projection to ERAS5 25km grid using WGS84 projection.


```{r}

```

# Data analysis and verification

```{r}
1 + 1
```

# Dataset building

##  era5-x0.25_A:
ERA5 data is provided at 0.25 x 0.25-degree resolution globally. This indicates it uses a regular latitude/longitude grid (WGS84/EPSG:4326).The 0.25-degree resolution means equal longitude spacing but decreasing latitude spacing towards poles

Panel with waves 2005-2022 for each NUTS1/NUTS2 region. 
Use population weights to aggregate the climate gridcell level data.
The population data comes from GHS data using as base the years of 2005,2015 and 2020. A linear arithmetic extrapolation is used to create years between the base years.

Population-weighted variable is produced by multiplying the value of the varaiable in a given cell with the population in the same cell, summing over the area, and the dividing by the total population in that area.

The API query function was parametrized with the following values:

| Variable | Code | Product | Scenarios | Aggregation | Model | Period | Type |
|----------|-------|----------|------------|-------------|--------|---------|------|
| Mean Temperature | tas | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Cooling Degree Days (>18°C/65°F) | cdd65 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Heating Degree Days (<18°C/65°F) | hdd65 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Hot Days (Tmax>30°C) | hd30 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Very Hot Days (Tmax>35°C) | hd35 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Frost Days (Tmin<0°C) | fd | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Ice Days (Tmax<0°C) | id | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Days with Precipitation >20mm | r20mm | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Days with Precipitation >50mm | r50mm | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Precipitation | pr | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |

Code process:

1. ERA5 climate data gets cropped to NUTS regions. Both NUTS levels converted to rasters matching ERA5 grid.

2. Cell area weights calculated for each grid cell, accounting for latitude variation. Separate masks for NUTS1 and NUTS2.

3. Population raster resampled to ERA5 grid then weighted by cell areas. Higher resolution preserved until needed.

4. Population data masked to each NUTS level. Maintains spatial relationship with administrative boundaries.

5. ERA5 data weighted by cell area then masked to NUTS regions. Division by weights_nuts normalizes values.

6. Time subset applied to match population years (2005-2020). Final weighted means calculated using population-weighted values per NUTS region per year.

Each step preserves spatial relationships while accounting for cell area variations by latitude.

This implements weighted mean as:
Σ(value × lat_weight × pop_weight) / Σ(lat_weight × pop_weight)

numerator = extract(era5_weighted, nuts1, fun='sum')  # Sum of weighted values
denominator = extract(weights * pop_era5, nuts1, fun='sum')  # Sum of weights
nuts1_means = numerator / denominator  # Weighted average


```{r era5_data_a}
#| echo: false


# Load data
source("NUTS.R")

eras5 <- terra::rast(here("Output", "climate_data_era5-x0.25_historical_era5_timeseries_1950-2022__combined.tif"))
crs(eras5) <- "EPSG:4326"
pop_raster <- terra::rast(here("Output","pop_raster_2005_2022.tif"))
crs(pop_raster) <- "EPSG:4326"
crs(nuts2) <- "EPSG:4326"
crs(nuts1) <- "EPSG:4326"

# Initial time dimension slicing for ERA5 to 2005-2022
subset_time <- terra::time(eras5) >= as.Date("2005-01-01")
eras5 <- eras5[[subset_time]]

# Crop ERA5 and pop_raster to NUTS extent
extent_to_match <- ext(nuts1)
eras5 <- crop(eras5, extent_to_match)
pop_raster <- crop(pop_raster, extent_to_match)

# Resample pop_raster to match the resolution of ERA5 using nearest neighbor
pop_raster <- resample(pop_raster, eras5, method = "near")

# Parallel processing function for each year
process_year <- function(year, eras5, pop_raster, nuts1, nuts2) {
  
  message("Processing year: ", year)
  
  era5_year <- eras5[as.character(year)]
  pop_year <- pop_raster[[paste0("pop_", year)]]
  
  era5_weighted <- era5_year
  
  nuts1_stats <- zonal(era5_weighted, nuts1, fun = "mean", na.rm = TRUE,
   w = pop_year, weights = TRUE, exact = TRUE, as.polygons = TRUE)
  
  nuts2_stats <- zonal(era5_weighted, nuts2, fun = "mean", na.rm = TRUE,
   w = pop_year, weights = TRUE, exact = TRUE, as.polygons = TRUE)
  
  return(list(nuts1_stats = nuts1_stats, nuts2_stats = nuts2_stats))
  gc()
}

results <- list()
 
for (year in 2005:2022) {
  results[[as.character(year)]] <- process_year(year, eras5, pop_raster, nuts1, nuts2)
}

# Extract results for NUTS1 and NUTS2
nuts1_results <- lapply(results, function(res) res$nuts1_stats)
nuts2_results <- lapply(results, function(res) res$nuts2_stats)

combined_nuts1 <- terra::vect(nuts1_results)
combined_nuts2 <- terra::vect(nuts2_results)

# Inspect the combined SpatVector objects
unique_nuts1 <- length(unique(nuts1$NUTS_ID))
unique_nuts2 <- length(unique(nuts2$NUTS_ID))

unique_combined_nuts1 <- length(unique(combined_nuts1$NUTS_ID))
unique_combined_nuts2 <- length(unique(combined_nuts2$NUTS_ID))

cat("NUTS1 and Combined NUTS1 have the same number of unique IDs:", unique_nuts1 == unique_combined_nuts1, "\n")
cat("NUTS2 and Combined NUTS2 have the same number of unique IDs:", unique_nuts2 == unique_combined_nuts2, "\n")

# Save the combined vector for NUTS1$2 as a single GeoPackage as it supports longer variable names
writeVector(combined_nuts1
            , here("Output", "era5_data_a_nuts1_w.gpkg")
            , overwrite = TRUE)
writeVector(combined_nuts2
            , here("Output", "era5_data_a_nuts2_w.gpkg")
            , overwrite = TRUE)

# Export results as Rds objects
saveRDS(combined_nuts1, here("Output","era5_data_a_nuts1_w.rds"))
saveRDS(combined_nuts2, here("Output", "era5_data_a_nuts2_w.rds"))

```

```{r verify_era5_data_a}

# Verify results
# Verify alignment, masking reviews extent
compareGeom(rast(era5_data_a_nuts1_w), rast(era5_data_a_nuts2_w))

# Verify temporal dimension
print(paste("Time steps in original:", nlyr(era5_europe)))
print(paste("Time steps in NUTS1:", nlyr(rast(era5_data_a_nuts1_w))))
print(paste("Time steps in NUTS2:", nlyr(rast(era5_data_a_nuts2_w))))

print("Weight statistics by latitude:")
# Sample weights at different latitudes to show variation
y_coords <- seq(min(as.vector(ext(era5_europe)[3:4])), 
                max(as.vector(ext(era5_europe)[3:4])), 
                length.out=5)
for(y in y_coords) {
  p <- vect(cbind(0, y), crs=crs(weights))
  w <- extract(weights, p)
  print(paste("Latitude:", round(y, 2), "Weight:", round(w[1,2], 2)))
}

# Verify coverage
print("\nVerifying NUTS coverage:")
print(paste("Number of NUTS1 regions with data:", 
           global(rast(era5_data_a_nuts1_w), fun="notNA")[1,1]))
print(paste("Number of NUTS2 regions with data:", 
           global(rast(era5_data_a_nuts2_w), fun="notNA")[1,1]))
```


```{r summary_era5_data_a}
# Summary stats across time periods
# Mean for each NUTS1 region across all time steps
means_nuts1 <- global(era5_data_a_nuts1, mean, na.rm = TRUE)

# Basic temporal stats
temporal_stats <- data.frame(
  min = global(era5_data_a_nuts1, min, na.rm = TRUE),
  max = global(era5_data_a_nuts1, max, na.rm = TRUE),
  mean = global(era5_data_a_nuts1, mean, na.rm = TRUE),
  sd = global(era5_data_a_nuts1, sd, na.rm = TRUE)
)

# Time series plot 
values <- terra::as.data.frame(era5_data_a_nuts1, xy = TRUE)
time_series <- ggplot(values, aes(x=seq_len(ncol(values)-2), y = value)) +
  geom_line() +
  theme_minimal() +
  labs(title="ERA5 Time Series by NUTS1 Region",
       x="Time Steps", 
       y="Value")

# Boxplot of values by region
box_plot <- ggplot(values, aes(y=value)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title="Distribution of ERA5 Values",
       y="Value")

print(temporal_stats)
print(time_series)
print(box_plot)
```


##  era5-x0.25_B:
Dataset with one value per variable for each NUTS1/NUTS2 region. 
We will add anomalues to this value to create future climate scenarios


The API query function was parametrized with the following values:

Caveat:pr available timeperiod is 1991-2020.

| Variable | Code | Product | Scenarios | Aggregation | Model | Period | Type |
|----------|-------|----------|------------|-------------|--------|---------|------|
| Mean Temperature | tas | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Cooling Degree Days (>18°C/65°F) | cdd65 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Heating Degree Days (<18°C/65°F) | hdd65 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Hot Days (Tmax>30°C) | hd30 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Very Hot Days (Tmax>35°C) | hd35 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Frost Days (Tmin<0°C) | fd | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Ice Days (Tmax<0°C) | id | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Days with Precipitation >20mm | r20mm | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Days with Precipitation >50mm | r50mm | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Precipitation | pr | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |

```{r era5-x0.25_b}


```


##  cmip6-x0.25_A:


We get the anolamy, which is then added to the current data (ERAS5) and then aggreated at NUTS2 and NUTS1 using future population projections

CCKP presents projection as absolute values and/or as anomalies (from the historical reference period: 1995-2014 for CMIP6)
Download the anomaly directly , just one point in time (climatology 2040-2059)



| Variable | Description | Product | Scenarios | Model | Period | Type |
|----------|------------|---------|-----------|--------|---------|-------|
| tas | Mean temperature | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| cdd65 | Cooling degree days (temp > 18°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| hdd65 | Heating degree days (temp < 18°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| hd30 | Number of hot days (Tmax > 30°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| hd35 | Number of very hot days (Tmax > 35°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| fd | Number of frost days (Tmin < 0°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| id | Number of ice days (Tmax < 0°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| r20mm | Days with precipitation > 20mm | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| r50mm | Days with precipitation > 50mm | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| pr | Precipitation | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |


```{r}

```

## cmip6-x0.25_B:

Las varaiables de precipitación usamos el cambio relativo, tenemos que calcularlo, nos falta los datos de base period simulation
Relative change= anomaly climatology / simulation base climatology



Future climate= climatology historic (1995-2014) + (CMIP climatology anomaly)

Future population= GHS 2020 + (popcount 2040-2059 - popcount 1995-2014). Es la anomalía calculada en el punto 2.

Con esas proyecciones, se puede agregar.

 

Para las variables de precipitación (pr, r20mm, r50mm) hay que aplicar el growth rate 

Future climate= climatology historic (1995-2014)* (1+ CMIP climatology anomaly/CMIP historic)

Because climate simulations do not reproduce observed high-frequency weather extremes, and may exhibit biases relative to current climate, we do not directly compare simulated future exposures against their observed counterparts, but instead employ the 'delta' change method of computing differences in exposure between simulated current and future climates. Namely:

![](Figures/download.png){.preview-image width="674" height="453"}
![](Figures/download1.png){.preview-image width="674" height="453"}




![](Figures/download2.png){.preview-image width="674" height="153"}
 

Vamos a tener que hacer eso para el clima y la población (a nivel grid) para luego obtener population weighted climate projections a nivel NUTS. En nuestro caso:

 

Future climate=Current climate (ERAS) + anomaly (CMIP)

Future population= Current population (GHS)+ anomaly (WB NASA population data)

| Collection | Variables | Product | Scenarios | Aggregation | Model | Time Period | Percentile | Product Type | Statistic |
|-----------|-----------|---------|-----------|-------------|-------|-------------|------------|--------------|------------|
| cmip6-x0.25_B | r20mm | Climatology | ssp245 & ssp585 | Annual | Ensemble_all | 1995-2014 | Median | Climatology | Mean number of days with precipitation > 20mm |
| cmip6-x0.25_B | r50mm | Climatology | ssp245 & ssp585 | Annual | Ensemble_all | 1995-2014 | Median | Climatology | Mean number of days with precipitation > 50mm |
| cmip6-x0.25_B | pr | Climatology | ssp245 & ssp585 | Annual | Ensemble_all | 1995-2014 | Median | Climatology | Mean Precipitation |


```{r Caclulation_proyectiosn}

# Load and calculating inputs

## Collection era5-xO.25_B: 1995-2014
era5_historic <- terra::rast(here("Output","climate_data_era5-x0.25_historical_era5_climatology_1995-2014__combined.tif"))
crs(era5_historic) <- "EPSG:4326" # 1995 VERIFY!!!!!!!!!

era5_historic_pr <- terra::rast(here("Output","climate_data_era5-x0.25_historical_era5_climatology_1991-2020_pr_combined.tif"))
crs(era5_historic_pr) <- "EPSG:4326" # 1991 VERIFY!!!!!!!!!

era5_historic_all <- c(era5_historic,era5_historic_pr)

## Collection era5-xO.25_A: 2005 -2022, panel data
era5_historic_panel <- terra::rast(here("Output","climate_data_era5-x0.25_historical_era5_timeseries_1950-2022__combined.tif"))
crs(era5_historic_panel) <- "EPSG:4326"

## Collection cmip6-xO.25 _B: 1995-2014
cmip6_historic <- terra::rast(here("Output", "climate_data_era5-x0.25_historical_era5_climatology_1995-2014__combined.tif"))
crs(cmip6_historic) <- "EPSG:4326"

## Collection cmip6-xO.25 _A: 2040-2059
cmip6_future <- terra::rast(here("Output", "climate_data_cmip6-x0.25_ssp245_ssp585_climatology_2040-2059__combined.tif"))
crs(cmip6_future) <- "EPSG:4326"

## popcount 2040-2059/2040 by scenario, at eras5 resolution
pop_fut_ssp585 <- terra::rast(here("Output","climatology-popcount-annual-mean_pop-x0.25_gpw-v4-rev11-ssp585_climatology_mean_2040-2059.nc"))
crs(pop_fut_ssp585) <- "EPSG:4326"

pop_fut_ssp245 <- terra::rast(here("Output","climatology-popcount-annual-mean_pop-x0.25_gpw-v4-rev11-ssp245_climatology_mean_2040-2059.nc"))
crs(pop_fut_ssp245) <- "EPSG:4326"

## popcount 1995-2014/ 1995pop_hist
pop_hist <- terra::rast(here("Output","climatology-popcount-annual-mean_pop-x0.25_gpw-v4-rev11-historical_climatology_mean_1995-2014.nc"))
crs(pop_hist) <- "EPSG:4326"

## Calculate anomaly population (popcount 2040-2059) – (popcount 1995-2014) for each scenario
# Verify extent and resolution match
compareGeom(pop_fut_ssp585, pop_hist)
compareGeom(pop_fut_ssp245, pop_hist)

summary(values(pop_fut_ssp585))

pop_anomaly_ssp585 <- pop_fut_ssp585 - pop_hist #Negative values!! REVIEW!!!!!!!!!!!!!!!
pop_anomaly_ssp245 <- pop_fut_ssp245 - pop_hist

# Change to nuts extent
pop_anomaly_ssp585 <- crop(pop_anomaly_ssp585, ext(nuts1))
pop_anomaly_ssp245 <- crop(pop_anomaly_ssp245, ext(nuts1))

writeCDF(pop_anomaly_ssp585, here("Output", "pop_anomaly_ssp585.nc")
         , varname = "pop_anomaly_ssp585"
         , longname = "Anomaly population scenario ssp585"
         , overwrite = TRUE)
writeCDF(pop_anomaly_ssp585, here("Output", "pop_anomaly_ssp585.nc")
         , varname = "pop_anomaly_ssp585"
         , longname = "Anomaly population scenario ssp585"
         , overwrite = TRUE)

## Calculate future population for each scenario

### Ensure same extent
pop_raster_ext <- crop(pop_raster, ext(nuts1))

### Then resample to convert to eras5 coarser resolution
extent_to_match <- ext(nuts1)
eras5 <- crop(eras5, extent_to_match)
pop_raster <- resample(pop_raster_ext, eras5, method = "near")

# Verify extent and resolution match
compareGeom(pop_anomaly_ssp585, pop_raster[["pop_2015"]])
compareGeom(pop_anomaly_ssp245, pop_raster[["pop_2015"]])

future_pop_ssp585 <- pop_raster[["pop_2015"]] + pop_anomaly_ssp585
future_pop_ssp245 <- pop_raster[["pop_2015"]] + pop_anomaly_ssp245

# Estimate future values by scenario

non_rain_vars <- c("tas", "cdd65", "hdd65", "hd30", "hd35", "fd", "id")
rain_vars <- c("r20mm", "r50mm", "pr")

# Scenarios ssp245 & ssp585 variables
names(cmip6_future) <- c(
  "anomaly-cdd65-annual-mean_2040_ssp245", "anomaly-cdd65-annual-mean_2040_ssp585",
  "anomaly-fd-annual-mean_2040_ssp245", "anomaly-fd-annual-mean_2040_ssp585",
  "anomaly-hd30-annual-mean_2040_ssp245", "anomaly-hd30-annual-mean_2040_ssp585",
  "anomaly-hd35-annual-mean_2040_ssp245", "anomaly-hd35-annual-mean_2040_ssp585",
  "anomaly-hdd65-annual-mean_2040_ssp245", "anomaly-hdd65-annual-mean_2040_ssp585",
  "anomaly-id-annual-mean_2040_ssp245", "anomaly-id-annual-mean_2040_ssp585",
  "anomaly-pr-annual-mean_2040_ssp245", "anomaly-pr-annual-mean_2040_ssp585",
  "anomaly-r20mm-annual-mean_2040_ssp245", "anomaly-r20mm-annual-mean_2040_ssp585",
  "anomaly-r50mm-annual-mean_2040_ssp245", "anomaly-r50mm-annual-mean_2040_ssp585",
  "anomaly-tas-annual-mean_2040_ssp245", "anomaly-tas-annual-mean_2040_ssp585"
)

## Scenario ssp585:
### Non-rain variables: sum anomaly to historic mean:
# Collection era5-xO.25_B + Collection cmip6-xO.25 _A

# Make extent equal to nuts1
era5_historic_all <- crop(era5_historic_all, ext(nuts1))
cmip6_future <- crop(cmip6_future, ext(nuts1)) 

era5_historic_all <- extend(era5_historic_all, ext(nuts1))
cmip6_future <- extend(cmip6_future, ext(nuts1))

# Select layers that contain non_rain_vars and are from ssp585
era5_historic_all <- era5_historic_all %>% rename( 
  "climatology-pr-annual-mean_1995" = "climatology-pr-annual-mean_1991"
  )
#### REVIEW "climatology-pr-annual-mean_1991" !!!
layer_names <- names(era5_historic_all)

(selected_layers_era5_historic_all <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x))))]
)

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x)) & grepl("ssp585", x)))]
)

future_ssp585 <- rast(nrow = nrow(cmip6_future)
                      , ncol = ncol(cmip6_future)
                      , nlyr = length(selected_layers_cmip6_future)
                      ) 
ext(future_ssp585) <- ext(cmip6_future) 
crs(future_ssp585) <- crs(cmip6_future)

future_ssp585 <- subset(era5_historic_all
                        , subset = selected_layers_era5_historic_all)
                + subset(cmip6_future
                        , subset = selected_layers_cmip6_future)

future_ssp585_nr <- future_ssp585
### Rain variables: use change wrt to historic mean:
# Deltha change: Collection cmip6-xO.25 _A/ Collection cmip6-xO.25 _B
cmip6_historic <- crop(cmip6_historic, ext(nuts1)) 
cmip6_historic <- extend(cmip6_historic, ext(nuts1))

# Select layers that contain rain_vars and are from ssp585
layer_names <- names(cmip6_historic)

(selected_layers_cmip6_historic_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x))))]
)
#### REVIEW "climatology-pr-annual-mean_1991" !!!

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x)) & grepl("ssp585", x)))]
)

# Collection era5-xO.25_B *(1+ Deltha change)

ratio <- (subset(cmip6_future
                          , subset = selected_layers_cmip6_future_r)/ subset(cmip6_historic , subset = selected_layers_cmip6_historic_r))
         
future_ssp585 <- subset(era5_historic_all
                                , subset = selected_layers_era5_historic_all
                                , negate = TRUE ) * (1 + ratio)

future_ssp585_r <- future_ssp585

future_ssp585 <- c(future_ssp585_nr, future_ssp585_r)
names(future_ssp585)

## Scenario ssp245:
layer_names <- names(era5_historic_all)

(selected_layers_era5_historic_all <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x))))]
)

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x)) & grepl("ssp245", x)))]
)

future_ssp245 <- rast(nrow = nrow(cmip6_future)
                      , ncol = ncol(cmip6_future)
                      , nlyr = length(selected_layers_cmip6_future)
                      ) 
ext(future_ssp245) <- ext(cmip6_future) 
crs(future_ssp245) <- crs(cmip6_future)

future_ssp245 <- subset(era5_historic_all
                        , subset = selected_layers_era5_historic_all)
                + subset(cmip6_future
                        , subset = selected_layers_cmip6_future)


future_ssp245_nr <- future_ssp245
  
### Rain variables: use change wrt to historic mean:
# Deltha change: Collection cmip6-xO.25 _A/ Collection cmip6-xO.25 _B
cmip6_historic <- crop(cmip6_historic, ext(nuts1)) 
cmip6_historic <- extend(cmip6_historic, ext(nuts1))

# Select layers that contain rain_vars and are from ssp245
layer_names <- names(cmip6_historic)

(selected_layers_cmip6_historic_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x))))]
)
#### REVIEW "climatology-pr-annual-mean_1991" !!!

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x)) & grepl("ssp245", x)))]
)

# Collection era5-xO.25_B *(1+ Deltha change)

ratio <- (subset(cmip6_future
                          , subset = selected_layers_cmip6_future_r)/ subset(cmip6_historic , subset = selected_layers_cmip6_historic_r))
         
future_ssp245 <- subset(era5_historic_all
                                , subset = selected_layers_era5_historic_all
                                , negate = TRUE ) * (1 + ratio)

future_ssp245_r <- future_ssp245

future_ssp245 <- c(future_ssp585_nr, future_ssp585_r)
names(future_ssp585)


### Population weighted future values
calculate_nuts_stats <- function(future_values, future_pop, nuts1, nuts2) {
  
  weighted_values <- future_values
  
  nuts1_stats <- zonal(weighted_values, nuts1, fun = "mean", na.rm = TRUE, w = future_pop, weights = TRUE, exact = TRUE, as.polygons = TRUE)
  
  nuts2_stats <- zonal(weighted_values, nuts2, fun = "mean", na.rm = TRUE, w = future_pop, weights = TRUE, exact = TRUE, as.polygons = TRUE)

  return(list(nuts1_stats = nuts1_stats, nuts2_stats = nuts2_stats))
}

# Calculate statistics for both scenarios
results_ssp585 <- calculate_nuts_stats(future_ssp585
                                       , future_pop_ssp585
                                       , nuts1
                                       , nuts2
                                       )

results_ssp245 <- calculate_nuts_stats(future_ssp245
                                       , future_pop_ssp245
                                       , nuts1
                                       , nuts2
                                       )

# Extract results for NUTS1 and NUTS2 for each scenario
combined_nuts1_ssp585 <- results_ssp585$nuts1_stats
combined_nuts2_ssp585 <- results_ssp585$nuts2_stats

combined_nuts1_ssp245 <- results_ssp245$nuts1_stats
combined_nuts2_ssp245 <- results_ssp245$nuts2_stats

# Save the combined vectors for each scenario
writeVector(combined_nuts1_ssp585, here("Output", "era5_data_ssp585_nuts1_w.gpkg"), overwrite = TRUE)
writeVector(combined_nuts2_ssp585, here("Output", "era5_data_ssp585_nuts2_w.gpkg"), overwrite = TRUE)

writeVector(combined_nuts1_ssp245, here("Output", "era5_data_ssp245_nuts1_w.gpkg"), overwrite = TRUE)
writeVector(combined_nuts2_ssp245, here("Output", "era5_data_ssp245_nuts2_w.gpkg"), overwrite = TRUE)

# Export results as Rds objects
saveRDS(combined_nuts1_ssp585, here("Output","era5_data_ssp585_nuts1_w.rds"))
saveRDS(combined_nuts2_ssp585, here("Output", "era5_data_ssp585_nuts2_w.rds"))

saveRDS(combined_nuts1_ssp245, here("Output","era5_data_ssp245_nuts1_w.rds"))
saveRDS(combined_nuts2_ssp245, here("Output", "era5_data_ssp245_nuts2_w.rds"))


```

# Export in terra, rds and csv
```{r}

# Function to process dataset
process_dataset <- function(data) {
  # Get columns that aren't part of the key
  value_cols <- names(data)[!names(data) %in% c("NUTS_ID", "LEVL_CODE", "CNTR_CODE", "NAME_LATN", "NUTS_NAME", "MOUNT_TYPE", "URBN_TYPE", "COAST_TYPE")]
  
  # Aggregate data
 as.data.frame(data) %>%
    group_by(NUTS_ID, LEVL_CODE, CNTR_CODE, NAME_LATN, NUTS_NAME, MOUNT_TYPE, URBN_TYPE, COAST_TYPE) %>%
    summarise(across(all_of(value_cols), ~toString(unique(na.omit(.x))))) %>%
    ungroup()
}

# Read and process each dataset
datasets <- c("era5_data_a_nuts1_w", "era5_data_a_nuts2_w", "era5_data_ssp585_nuts1_w", "era5_data_ssp585_nuts2_w", "era5_data_ssp245_nuts1_w", "era5_data_ssp245_nuts2_w")

Sys.setlocale("LC_ALL", "UTF-8")

for(dataset_name in datasets) {
  data <- readRDS(here("Output", paste0(dataset_name, ".rds")))
  result <- process_dataset(data)
  
  write_csv(result, 
            here("Output", paste0("processed_", dataset_name, ".csv")),
            na = "",
            quote = "all"
            )
}
```

