---
title: "Technical documentation NUTS1&2 level environmental data"
author: "Andrei Wong Espejo"
format: docx
editor: visual
bibliography: references.bib
---

<!-- using quarto install extension quarto-monash/report -->

<!-- using quarto install extension schochastics/academicons -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Prevent scientific notation
options(scipen = 999)

# Load required packages ----
require(quartotemplate)


```

# Introduction:

The following code combines ERA5 climate data, population data and NUTS boundaries to create climate indicators at nuts1 and nuts2 region level.

# Workflow description:

This code creates four climate datasets for EU NUTS regions level 1 and 2. The workflow aggregates 1km population data to 25km climate grid while preserving population totals. The objective is to create a panel series for 2005-2022 with latitudinal and population weighted climate variables and a dataset with future projections. This projections combine historical ERA5 data with CMIP6 anomalies, using different methods for no-precipitation (additive) and precipitation variable (delta method), for each future climate scenario and NUTS region level. Results are exported in vector, RDS and tabular formats.

To obtain this we need to extract the following data:

era5-x0.25_A: - Panel dataset for 2005-2022 - Ten climate indicators across NUTS regions - Population weighted using GHS data - Three base years (2005/2015/2020) with interpolation

era5-x0.25_B: - Single baseline value per region - Reference period 1995-2014 - Provides foundation for projections

cmip6-x0.25_A: - Future projections for 2040-2059 - Two scenarios: SSP245 and SSP585 - Anomalies relative to baseline - Uses scenario-specific populations

cmip6-x0.25_B: - Historical CMIP6 data 1995-2014 - Used for precipitation projections - Enables relative change calculations

pop_x0.25_future and pop_x0.25_future: - Future population projections for 2040-2059 - Two scenarios: SSP245 and SSP585

# Obtaining data:

Three main inputs:

GHS Population: 1km resolution population grid in Mollweide projection spanning 1975-2030. Gridded data enables consistent integration, stable cells over time, and custom zone aggregation. GHS (2023) Epochs: c(1975, 1980, 1985, 1990, 1995, 2000, 2005, 2005, 2015, 2020, 2025, 2030) Resolution: 1km Coordinate System: ESPG: 4326

ERA5: High-resolution climate and population data. Resolution: 0.25 by 0.25 degrees Coordinate System: Mollweide

NUTS1/2 (2016): Administrative boundaries defining statistical regions. Resolution: 20M Coordinate System: ESPG: 4326

# Data cleaning and wrangling principal operations:

The spatial analysis operations to perform are:

-   Aggregation: change of scale of the information, from 1km GHS population grid to 25km ERAS5 grid/cmip6-x0.25 grid. This means the reprojection of population grids maintaining volumes and minimising displacement of population.

-   Zonal statistics: Aggregation of rasters by zones, at the NUTS1&2 regions. It is important to weight the summary of grid values by latitudinal and population weighting, other weights can be considered (density, economic activity, etc.).

\_ Masking and cropping: One critical aspect of population grids is that they represent a given spatial distribution and volume of people (i.e. total number of persons) for the area being represented. When the boundaries intersect grids masking zeroes out values outside of the area of interest and cropping cuts the extent of the area.

The has taken into consideration that latitudinal weighting and area weighting are proportional, see \@

Finally, wile doing the spatial aggregation, we need to decide whether we want to transform the data first and then aggregate it (transformation-before-aggregation) or aggregate it and then transform it (aggregation-before-transformation). It matters what variable is under consideration. For example, doing aggregation-before-transformation for temperature will distort the signal less than doing it for precipitation. This is because precipitation is highly local both temporally and spatially (it could rain for \<1 min in \<1 km radius area). As indicated by

# Data analysis and verification

# Dataset building

The code snippets generate the following:

era5-x0.25_A Panel dataset 2005-2022 with population-weighted climate variables. Uses GHS population for 2005, 2015, 2020 with linear interpolation between years. Processes 10 climate indicators including temperature, precipitation and extreme events.

era5-x0.25_B Single value per region for 1995-2014 baseline period. Creates foundation for future projections. cmip6-x0.25_A

Anomalies for 2040-2059 under two scenarios:

SSP245 (moderate climate change) SSP585 (severe climate change)

cmip6-x0.25_B CMIP6 historical data (1995-2014) used for relative precipitation changes.

Future climate calculated:

Temperature variables: ERA5 historical + CMIP6 anomaly Precipitation: ERA5 historical \* (1 + relative change) Population weighted using scenario-specific projection

## era5-x0.25_A:

ERA5 data is provided at 0.25 x 0.25-degree resolution globally. This indicates it uses a regular latitude/longitude grid (WGS84/EPSG:4326).The 0.25-degree resolution means equal longitude spacing but decreasing latitude spacing towards poles

Panel with waves 2005-2022 for each NUTS1/NUTS2 region. Use population weights to aggregate the climate gridcell level data. The population data comes from GHS data using as base the years of 2005, 2015 and 2020. A linear arithmetic extrapolation is used to create years between the base years.

Population-weighted variable is produced by multiplying the value of the varaiable in a given cell with the population in the same cell, summing over the area, and the dividing by the total population in that area.

The API query function was parametrized with the following values:

| Variable | Code | Product | Scenarios | Aggregation | Model | Period | Type |
|---------|---------|---------|---------|---------|---------|---------|---------|
| Mean Temperature | tas | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Cooling Degree Days (\>18°C/65°F) | cdd65 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Heating Degree Days (\<18°C/65°F) | hdd65 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Hot Days (Tmax\>30°C) | hd30 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Very Hot Days (Tmax\>35°C) | hd35 | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Frost Days (Tmin\<0°C) | fd | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Ice Days (Tmax\<0°C) | id | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Days with Precipitation \>20mm | r20mm | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Days with Precipitation \>50mm | r50mm | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |
| Precipitation | pr | timeseries | historical_era5 | annual | Ensemble_all | 1950-2022 | timeseries |

Each step preserves spatial relationships while accounting for cell area variations by latitude.

This implements weighted mean as: Σ(value × lat_weight × pop_weight) / Σ(lat_weight × pop_weight)

Hence the following code process ERA5 data to NUTS regions: 1. Load and prepare spatial data 2. Crop ERA5 and population raster to match NUTS extent\
3. Resample population to ERA5 resolution 4. Create parallel processing function for each year 5. Compute population weighted means by NUTS region 6. Save results as GeoPackage and RDS files

```{r era5_data_a}
#| echo: false


# Load data
source("NUTS.R")

eras5 <- terra::rast(here("Output", "climate_data_era5-x0.25_historical_era5_timeseries_1950-2022__combined.tif"))
crs(eras5) <- "EPSG:4326"
pop_raster <- terra::rast(here("Output","pop_raster_2005_2022.tif"))
crs(pop_raster) <- "EPSG:4326"
crs(nuts2) <- "EPSG:4326"
crs(nuts1) <- "EPSG:4326"

# Initial time dimension slicing for ERA5 to 2005-2022
subset_time <- terra::time(eras5) >= as.Date("2005-01-01")
eras5 <- eras5[[subset_time]]

# Crop ERA5 and pop_raster to NUTS extent
extent_to_match <- ext(nuts1)
eras5 <- crop(eras5, extent_to_match)
pop_raster <- crop(pop_raster, extent_to_match)

# Resample pop_raster to match the resolution of ERA5 using nearest neighbor
pop_raster <- resample(pop_raster, eras5, method = "near")

# Parallel processing function for each year
process_year <- function(year, eras5, pop_raster, nuts1, nuts2) {
  
  message("Processing year: ", year)
  
  era5_year <- eras5[as.character(year)]
  pop_year <- pop_raster[[paste0("pop_", year)]]
  
  era5_weighted <- era5_year
  
  nuts1_stats <- zonal(era5_weighted, nuts1, fun = "mean", na.rm = TRUE,
   w = pop_year, weights = TRUE, exact = TRUE, as.polygons = TRUE)
  
  nuts2_stats <- zonal(era5_weighted, nuts2, fun = "mean", na.rm = TRUE,
   w = pop_year, weights = TRUE, exact = TRUE, as.polygons = TRUE)
  
  return(list(nuts1_stats = nuts1_stats, nuts2_stats = nuts2_stats))
  gc()
}

results <- list()
 
for (year in 2005:2022) {
  results[[as.character(year)]] <- process_year(year, eras5, pop_raster, nuts1, nuts2)
}

# Extract results for NUTS1 and NUTS2
nuts1_results <- lapply(results, function(res) res$nuts1_stats)
nuts2_results <- lapply(results, function(res) res$nuts2_stats)

combined_nuts1 <- terra::vect(nuts1_results)
combined_nuts2 <- terra::vect(nuts2_results)

# Inspect the combined SpatVector objects
unique_nuts1 <- length(unique(nuts1$NUTS_ID))
unique_nuts2 <- length(unique(nuts2$NUTS_ID))

unique_combined_nuts1 <- length(unique(combined_nuts1$NUTS_ID))
unique_combined_nuts2 <- length(unique(combined_nuts2$NUTS_ID))

cat("NUTS1 and Combined NUTS1 have the same number of unique IDs:", unique_nuts1 == unique_combined_nuts1, "\n")
cat("NUTS2 and Combined NUTS2 have the same number of unique IDs:", unique_nuts2 == unique_combined_nuts2, "\n")

# Save the combined vector for NUTS1$2 as a single GeoPackage as it supports longer variable names
writeVector(combined_nuts1
            , here("Output", "era5_data_a_nuts1_w.gpkg")
            , overwrite = TRUE)
writeVector(combined_nuts2
            , here("Output", "era5_data_a_nuts2_w.gpkg")
            , overwrite = TRUE)

# Export results as Rds objects
saveRDS(combined_nuts1, here("Output","era5_data_a_nuts1_w.rds"))
saveRDS(combined_nuts2, here("Output", "era5_data_a_nuts2_w.rds"))

```

The following code snipped does validation checks:

1.  Compare geometry between NUTS1/NUTS2 results
2.  Count time steps in original vs processed data
3.  Calculate weight statistics at different latitudes\
4.  Verify number of NUTS regions with data

```{r verify_era5_data_a}

# Verify results
# Verify alignment, masking reviews extent
compareGeom(rast(era5_data_a_nuts1_w), rast(era5_data_a_nuts2_w))

# Verify temporal dimension
print(paste("Time steps in original:", nlyr(era5_europe)))
print(paste("Time steps in NUTS1:", nlyr(rast(era5_data_a_nuts1_w))))
print(paste("Time steps in NUTS2:", nlyr(rast(era5_data_a_nuts2_w))))

print("Weight statistics by latitude:")
# Sample weights at different latitudes to show variation
y_coords <- seq(min(as.vector(ext(era5_europe)[3:4])), 
                max(as.vector(ext(era5_europe)[3:4])), 
                length.out=5)
for(y in y_coords) {
  p <- vect(cbind(0, y), crs=crs(weights))
  w <- extract(weights, p)
  print(paste("Latitude:", round(y, 2), "Weight:", round(w[1,2], 2)))
}

# Verify coverage
print("\nVerifying NUTS coverage:")
print(paste("Number of NUTS1 regions with data:", 
           global(rast(era5_data_a_nuts1_w), fun="notNA")[1,1]))
print(paste("Number of NUTS2 regions with data:", 
           global(rast(era5_data_a_nuts2_w), fun="notNA")[1,1]))
```

The following code sippet generates a summary statistics and plots:

1.  Calculate means for NUTS1 regions across time
2.  Compute temporal statistics (min, max, mean, sd)
3.  Create time series plot of values
4.  Generate boxplot of value distributions

```{r summary_era5_data_a}
# Summary stats across time periods
# Mean for each NUTS1 region across all time steps
means_nuts1 <- global(era5_data_a_nuts1, mean, na.rm = TRUE)

# Basic temporal stats
temporal_stats <- data.frame(
  min = global(era5_data_a_nuts1, min, na.rm = TRUE),
  max = global(era5_data_a_nuts1, max, na.rm = TRUE),
  mean = global(era5_data_a_nuts1, mean, na.rm = TRUE),
  sd = global(era5_data_a_nuts1, sd, na.rm = TRUE)
)

# Time series plot 
values <- terra::as.data.frame(era5_data_a_nuts1, xy = TRUE)
time_series <- ggplot(values, aes(x=seq_len(ncol(values)-2), y = value)) +
  geom_line() +
  theme_minimal() +
  labs(title="ERA5 Time Series by NUTS1 Region",
       x="Time Steps", 
       y="Value")

# Boxplot of values by region
box_plot <- ggplot(values, aes(y=value)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title="Distribution of ERA5 Values",
       y="Value")

print(temporal_stats)
print(time_series)
print(box_plot)
```

## era5-x0.25_B:

Dataset with one value per variable for each NUTS1/NUTS2 region. This information willb be added to anomalues to create future climate scenarios.

The API query function was parametrized with the following values:

Caveat:pr available timeperiod is 1991-2020.

| Variable | Code | Product | Scenarios | Aggregation | Model | Period | Type |
|---------|---------|---------|---------|---------|---------|---------|---------|
| Mean Temperature | tas | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Cooling Degree Days (\>18°C/65°F) | cdd65 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Heating Degree Days (\<18°C/65°F) | hdd65 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Hot Days (Tmax\>30°C) | hd30 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Very Hot Days (Tmax\>35°C) | hd35 | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Frost Days (Tmin\<0°C) | fd | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Ice Days (Tmax\<0°C) | id | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Days with Precipitation \>20mm | r20mm | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Days with Precipitation \>50mm | r50mm | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |
| Precipitation | pr | Climatology | historical_era5 | annual | Ensemble_all | 1995-2014 | climatology |

## cmip6-x0.25_A:

We get the anomaly, which is then added to the current data (ERAS5) and then aggreated at NUTS2 and NUTS1 using future population projections

CCKP presents projection as absolute values and/or as anomalies (from the historical reference period: 1995-2014 for CMIP6) Download the anomaly directly, just one point in time (climatology 2040-2059). The API query function was parametrized with the following values:

| Variable | Description | Product | Scenarios | Model | Period | Type |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| tas | Mean temperature | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| cdd65 | Cooling degree days (temp \> 18°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| hdd65 | Heating degree days (temp \< 18°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| hd30 | Number of hot days (Tmax \> 30°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| hd35 | Number of very hot days (Tmax \> 35°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| fd | Number of frost days (Tmin \< 0°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| id | Number of ice days (Tmax \< 0°C) | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| r20mm | Days with precipitation \> 20mm | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| r50mm | Days with precipitation \> 50mm | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |
| pr | Precipitation | anomaly | ssp245 & ssp585 | Ensemble_all | 2040-2059 | climatology |

## cmip6-x0.25_B:

The API query function was parametrized with the following values:

| Collection | Variables | Product | Scenarios | Aggregation | Model | Time Period | Percentile | Product Type | Statistic |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| cmip6-x0.25_B | r20mm | Climatology | ssp245 & ssp585 | Annual | Ensemble_all | 1995-2014 | Median | Climatology | Mean number of days with precipitation \> 20mm |
| cmip6-x0.25_B | r50mm | Climatology | ssp245 & ssp585 | Annual | Ensemble_all | 1995-2014 | Median | Climatology | Mean number of days with precipitation \> 50mm |
| cmip6-x0.25_B | pr | Climatology | ssp245 & ssp585 | Annual | Ensemble_all | 1995-2014 | Median | Climatology | Mean Precipitation |

For future scenarios we have used the following definitions:

Future climate = climatology historic (1995-2014) + CMIP_climatology anomaly

Future population = GHS 2020 + (popcount 2040-2059 - popcount 1995-2014).

Now we consider for each scenario the following:

Because climate simulations do not reproduce observed high-frequency weather extremes, and may exhibit biases relative to current climate, we do not directly compare simulated future exposures against their observed counterparts, but instead employ the 'delta' change method of computing differences in exposure between simulated current and future climates. Namely:

![](Figures/download.png){.preview-image width="674" height="253"} 

![](Figures/download1.png){.preview-image width="674" height="253"}

![](Figures/download2.png){.preview-image width="674" height="153"}

Hence, for precipitation related variables (pr, r20mm, r50mm) we apply growth rate and for non-precipitation variables we sum the historic and future mean. Therefore for each future scenario:

Future climate\[rain\] = climatology historic (1995-2014) \* (1+ CMIP climatology anomaly/CMIP historic)

Future climate\[non-rain\] = Collection era5-xO.25_B + Collection cmip6-xO.25_A

The following code snippet create future scenarios: 1. Load historical and future climate/population data 2. Calculate population anomalies per scenario 3. Process non-rain variables by adding anomalies 4. Process rain variables using relative changes 5. Weight results using scenario populations 6. Save NUTS1/NUTS2 outputs for both scenarios

```{r Caclulation_proyectiosn}

# Load and calculating inputs

## Collection era5-xO.25_B: 1995-2014
era5_historic <- terra::rast(here("Output","climate_data_era5-x0.25_historical_era5_climatology_1995-2014__combined.tif"))
crs(era5_historic) <- "EPSG:4326" # 1995 VERIFY!!!!!!!!!

era5_historic_pr <- terra::rast(here("Output","climate_data_era5-x0.25_historical_era5_climatology_1991-2020_pr_combined.tif"))
crs(era5_historic_pr) <- "EPSG:4326" # 1991 VERIFY!!!!!!!!!

era5_historic_all <- c(era5_historic,era5_historic_pr)

## Collection era5-xO.25_A: 2005 -2022, panel data
era5_historic_panel <- terra::rast(here("Output","climate_data_era5-x0.25_historical_era5_timeseries_1950-2022__combined.tif"))
crs(era5_historic_panel) <- "EPSG:4326"

## Collection cmip6-xO.25 _B: 1995-2014
cmip6_historic <- terra::rast(here("Output", "climate_data_era5-x0.25_historical_era5_climatology_1995-2014__combined.tif"))
crs(cmip6_historic) <- "EPSG:4326"

## Collection cmip6-xO.25 _A: 2040-2059
cmip6_future <- terra::rast(here("Output", "climate_data_cmip6-x0.25_ssp245_ssp585_climatology_2040-2059__combined.tif"))
crs(cmip6_future) <- "EPSG:4326"

## popcount 2040-2059/2040 by scenario, at eras5 resolution
pop_fut_ssp585 <- terra::rast(here("Output","climatology-popcount-annual-mean_pop-x0.25_gpw-v4-rev11-ssp585_climatology_mean_2040-2059.nc"))
crs(pop_fut_ssp585) <- "EPSG:4326"

pop_fut_ssp245 <- terra::rast(here("Output","climatology-popcount-annual-mean_pop-x0.25_gpw-v4-rev11-ssp245_climatology_mean_2040-2059.nc"))
crs(pop_fut_ssp245) <- "EPSG:4326"

## popcount 1995-2014/ 1995pop_hist
pop_hist <- terra::rast(here("Output","climatology-popcount-annual-mean_pop-x0.25_gpw-v4-rev11-historical_climatology_mean_1995-2014.nc"))
crs(pop_hist) <- "EPSG:4326"

## Calculate anomaly population (popcount 2040-2059) – (popcount 1995-2014) for each scenario
# Verify extent and resolution match
compareGeom(pop_fut_ssp585, pop_hist)
compareGeom(pop_fut_ssp245, pop_hist)

summary(values(pop_fut_ssp585))

pop_anomaly_ssp585 <- pop_fut_ssp585 - pop_hist #Negative values!! REVIEW!!!!!!!!!!!!!!!
pop_anomaly_ssp245 <- pop_fut_ssp245 - pop_hist

# Change to nuts extent
pop_anomaly_ssp585 <- crop(pop_anomaly_ssp585, ext(nuts1))
pop_anomaly_ssp245 <- crop(pop_anomaly_ssp245, ext(nuts1))

writeCDF(pop_anomaly_ssp585, here("Output", "pop_anomaly_ssp585.nc")
         , varname = "pop_anomaly_ssp585"
         , longname = "Anomaly population scenario ssp585"
         , overwrite = TRUE)
writeCDF(pop_anomaly_ssp585, here("Output", "pop_anomaly_ssp585.nc")
         , varname = "pop_anomaly_ssp585"
         , longname = "Anomaly population scenario ssp585"
         , overwrite = TRUE)

## Calculate future population for each scenario

### Ensure same extent
pop_raster_ext <- crop(pop_raster, ext(nuts1))

### Then resample to convert to eras5 coarser resolution
extent_to_match <- ext(nuts1)
eras5 <- crop(eras5, extent_to_match)
pop_raster <- resample(pop_raster_ext, eras5, method = "near")

# Verify extent and resolution match
compareGeom(pop_anomaly_ssp585, pop_raster[["pop_2015"]])
compareGeom(pop_anomaly_ssp245, pop_raster[["pop_2015"]])

future_pop_ssp585 <- pop_raster[["pop_2015"]] + pop_anomaly_ssp585
future_pop_ssp245 <- pop_raster[["pop_2015"]] + pop_anomaly_ssp245

# Estimate future values by scenario

non_rain_vars <- c("tas", "cdd65", "hdd65", "hd30", "hd35", "fd", "id")
rain_vars <- c("r20mm", "r50mm", "pr")

# Scenarios ssp245 & ssp585 variables
names(cmip6_future) <- c(
  "anomaly-cdd65-annual-mean_2040_ssp245", "anomaly-cdd65-annual-mean_2040_ssp585",
  "anomaly-fd-annual-mean_2040_ssp245", "anomaly-fd-annual-mean_2040_ssp585",
  "anomaly-hd30-annual-mean_2040_ssp245", "anomaly-hd30-annual-mean_2040_ssp585",
  "anomaly-hd35-annual-mean_2040_ssp245", "anomaly-hd35-annual-mean_2040_ssp585",
  "anomaly-hdd65-annual-mean_2040_ssp245", "anomaly-hdd65-annual-mean_2040_ssp585",
  "anomaly-id-annual-mean_2040_ssp245", "anomaly-id-annual-mean_2040_ssp585",
  "anomaly-pr-annual-mean_2040_ssp245", "anomaly-pr-annual-mean_2040_ssp585",
  "anomaly-r20mm-annual-mean_2040_ssp245", "anomaly-r20mm-annual-mean_2040_ssp585",
  "anomaly-r50mm-annual-mean_2040_ssp245", "anomaly-r50mm-annual-mean_2040_ssp585",
  "anomaly-tas-annual-mean_2040_ssp245", "anomaly-tas-annual-mean_2040_ssp585"
)

## Scenario ssp585:
### Non-rain variables: sum anomaly to historic mean:
# Collection era5-xO.25_B + Collection cmip6-xO.25 _A

# Make extent equal to nuts1
era5_historic_all <- crop(era5_historic_all, ext(nuts1))
cmip6_future <- crop(cmip6_future, ext(nuts1)) 

era5_historic_all <- extend(era5_historic_all, ext(nuts1))
cmip6_future <- extend(cmip6_future, ext(nuts1))

# Select layers that contain non_rain_vars and are from ssp585
era5_historic_all <- era5_historic_all %>% rename( 
  "climatology-pr-annual-mean_1995" = "climatology-pr-annual-mean_1991"
  )
#### REVIEW "climatology-pr-annual-mean_1991" !!!
layer_names <- names(era5_historic_all)

(selected_layers_era5_historic_all <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x))))]
)

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x)) & grepl("ssp585", x)))]
)

future_ssp585 <- rast(nrow = nrow(cmip6_future)
                      , ncol = ncol(cmip6_future)
                      , nlyr = length(selected_layers_cmip6_future)
                      ) 
ext(future_ssp585) <- ext(cmip6_future) 
crs(future_ssp585) <- crs(cmip6_future)

future_ssp585 <- subset(era5_historic_all
                        , subset = selected_layers_era5_historic_all)
                + subset(cmip6_future
                        , subset = selected_layers_cmip6_future)

future_ssp585_nr <- future_ssp585

### Rain variables: use change wrt to historic mean:
# Deltha change: Collection cmip6-xO.25 _A/ Collection cmip6-xO.25 _B
cmip6_historic <- crop(cmip6_historic, ext(nuts1)) 
cmip6_historic <- extend(cmip6_historic, ext(nuts1))

# Select layers that contain rain_vars and are from ssp585
layer_names <- names(cmip6_historic)

(selected_layers_cmip6_historic_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x))))]
)
#### REVIEW "climatology-pr-annual-mean_1991" !!!

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x)) & grepl("ssp585", x)))]
)

# Collection era5-xO.25_B *(1+ Deltha change)

ratio <- (subset(cmip6_future
                          , subset = selected_layers_cmip6_future_r)/ subset(cmip6_historic , subset = selected_layers_cmip6_historic_r))
         
future_ssp585 <- subset(era5_historic_all
                                , subset = selected_layers_era5_historic_all
                                , negate = TRUE ) * (1 + ratio)

future_ssp585_r <- future_ssp585

future_ssp585 <- c(future_ssp585_nr, future_ssp585_r)
names(future_ssp585)

## Scenario ssp245:
layer_names <- names(era5_historic_all)

(selected_layers_era5_historic_all <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x))))]
)

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future <- layer_names[sapply(layer_names, function(x) any(sapply(non_rain_vars, function(var) grepl(var, x)) & grepl("ssp245", x)))]
)

future_ssp245 <- rast(nrow = nrow(cmip6_future)
                      , ncol = ncol(cmip6_future)
                      , nlyr = length(selected_layers_cmip6_future)
                      ) 
ext(future_ssp245) <- ext(cmip6_future) 
crs(future_ssp245) <- crs(cmip6_future)

future_ssp245 <- subset(era5_historic_all
                        , subset = selected_layers_era5_historic_all)
                + subset(cmip6_future
                        , subset = selected_layers_cmip6_future)


future_ssp245_nr <- future_ssp245
  
### Rain variables: use change wrt to historic mean:
# Deltha change: Collection cmip6-xO.25 _A/ Collection cmip6-xO.25 _B
cmip6_historic <- crop(cmip6_historic, ext(nuts1)) 
cmip6_historic <- extend(cmip6_historic, ext(nuts1))

# Select layers that contain rain_vars and are from ssp245
layer_names <- names(cmip6_historic)

(selected_layers_cmip6_historic_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x))))]
)
#### REVIEW "climatology-pr-annual-mean_1991" !!!

layer_names <- names(cmip6_future)

(selected_layers_cmip6_future_r <- layer_names[sapply(layer_names, function(x) any(sapply(rain_vars, function(var) grepl(var, x)) & grepl("ssp245", x)))]
)

# Collection era5-xO.25_B *(1+ Deltha change)

ratio <- (subset(cmip6_future
                          , subset = selected_layers_cmip6_future_r)/ subset(cmip6_historic , subset = selected_layers_cmip6_historic_r))
         
future_ssp245 <- subset(era5_historic_all
                                , subset = selected_layers_era5_historic_all
                                , negate = TRUE ) * (1 + ratio)

future_ssp245_r <- future_ssp245

future_ssp245 <- c(future_ssp585_nr, future_ssp585_r)
names(future_ssp585)


### Population weighted future values
calculate_nuts_stats <- function(future_values, future_pop, nuts1, nuts2) {
  
  weighted_values <- future_values
  
  nuts1_stats <- zonal(weighted_values, nuts1, fun = "mean", na.rm = TRUE, w = future_pop, weights = TRUE, exact = TRUE, as.polygons = TRUE)
  
  nuts2_stats <- zonal(weighted_values, nuts2, fun = "mean", na.rm = TRUE, w = future_pop, weights = TRUE, exact = TRUE, as.polygons = TRUE)

  return(list(nuts1_stats = nuts1_stats, nuts2_stats = nuts2_stats))
}

# Calculate statistics for both scenarios
results_ssp585 <- calculate_nuts_stats(future_ssp585
                                       , future_pop_ssp585
                                       , nuts1
                                       , nuts2
                                       )

results_ssp245 <- calculate_nuts_stats(future_ssp245
                                       , future_pop_ssp245
                                       , nuts1
                                       , nuts2
                                       )

# Extract results for NUTS1 and NUTS2 for each scenario
combined_nuts1_ssp585 <- results_ssp585$nuts1_stats
combined_nuts2_ssp585 <- results_ssp585$nuts2_stats

combined_nuts1_ssp245 <- results_ssp245$nuts1_stats
combined_nuts2_ssp245 <- results_ssp245$nuts2_stats

# Save the combined vectors for each scenario
writeVector(combined_nuts1_ssp585, here("Output", "era5_data_ssp585_nuts1_w.gpkg"), overwrite = TRUE)
writeVector(combined_nuts2_ssp585, here("Output", "era5_data_ssp585_nuts2_w.gpkg"), overwrite = TRUE)

writeVector(combined_nuts1_ssp245, here("Output", "era5_data_ssp245_nuts1_w.gpkg"), overwrite = TRUE)
writeVector(combined_nuts2_ssp245, here("Output", "era5_data_ssp245_nuts2_w.gpkg"), overwrite = TRUE)

# Export results as Rds objects
saveRDS(combined_nuts1_ssp585, here("Output","era5_data_ssp585_nuts1_w.rds"))
saveRDS(combined_nuts2_ssp585, here("Output", "era5_data_ssp585_nuts2_w.rds"))

saveRDS(combined_nuts1_ssp245, here("Output","era5_data_ssp245_nuts1_w.rds"))
saveRDS(combined_nuts2_ssp245, here("Output", "era5_data_ssp245_nuts2_w.rds"))


```

# Export in terra, rds and csv

```{r export}

# Function to process dataset
process_dataset <- function(data) {
  # Get columns that aren't part of the key
  value_cols <- names(data)[!names(data) %in% c("NUTS_ID", "LEVL_CODE", "CNTR_CODE", "NAME_LATN", "NUTS_NAME", "MOUNT_TYPE", "URBN_TYPE", "COAST_TYPE")]
  
  # Aggregate data
 as.data.frame(data) %>%
    group_by(NUTS_ID, LEVL_CODE, CNTR_CODE, NAME_LATN, NUTS_NAME, MOUNT_TYPE, URBN_TYPE, COAST_TYPE) %>%
    summarise(across(all_of(value_cols), ~toString(unique(na.omit(.x))))) %>%
    ungroup()
}

# Read and process each dataset
datasets <- c("era5_data_a_nuts1_w", "era5_data_a_nuts2_w", "era5_data_ssp585_nuts1_w", "era5_data_ssp585_nuts2_w", "era5_data_ssp245_nuts1_w", "era5_data_ssp245_nuts2_w")

Sys.setlocale("LC_ALL", "UTF-8")

for(dataset_name in datasets) {
  data <- readRDS(here("Output", paste0(dataset_name, ".rds")))
  result <- process_dataset(data)
  
  write_csv(result, 
            here("Output", paste0("processed_", dataset_name, ".csv")),
            na = "",
            quote = "all"
            )
}
```

# References

::: {#refs}
:::
